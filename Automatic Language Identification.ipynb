{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyrubberband as pyrb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import torchvision\n",
    "from sklearn.utils import shuffle\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeuDataset(Dataset):\n",
    "    '''Inicialização\n",
    "    \n",
    "    Nota que devemos croppar para 220500 p/ aumentar o batch size.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, rootPath, csvPath):\n",
    "        self.csvData = pd.read_csv(csvPath, delimiter=';')\n",
    "        self.rootPath = rootPath\n",
    "        self.list_IDs = self.csvData.iloc[:, 0]\n",
    "        self.labels = self.csvData.iloc[:, 1]\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Número total de amostras'''\n",
    "        return self.csvData.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Gera uma amostra da lista'\n",
    "        # Carrega a amostra e pega a label\n",
    "        X = torchaudio.load(self.rootPath + self.list_IDs[index])\n",
    "        y = self.labels[index]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def toSpectogram(self, index):\n",
    "        return self[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    '''Baseada no paper CRNN'''\n",
    "\n",
    "    def __init__(self, D_in):\n",
    "        super(CRNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(64, 3, (3, 3))\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'toSpectogram'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-846e18a7f19b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# torchaudio.transforms.Spectrogram(dataset[0][0][0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSpectogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'toSpectogram'"
     ]
    }
   ],
   "source": [
    "dataset = MeuDataset(\n",
    "    \"./data/\", \"./data/spoken-language-identification/training.csv\")\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "# torchaudio.transforms.Spectrogram(dataset[0][0][0])\n",
    "dataset[0][0][0].toSpectogram()\n",
    "\n",
    "\n",
    "#D = librosa.amplitude_to_db(np.abs(librosa.stft(a)), ref=np.max)\n",
    "\n",
    "#librosa.amplitude_to_db(np.abs(librosa.stft(dataset[0][0][0].numpy())), ref=np.max)\n",
    "#model = CRNN()\n",
    "#loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer = torch.optim.Adam(model.params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [[tensor([[[ 0.0317,  0.0431,  0.0517,  ..., -0.0026, -0.0040, -0.0043]]]), tensor([22050])], ('alemao',)]\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(dataloader):\n",
    "    \n",
    "    \n",
    "    if i == 2:\n",
    "        print(i, j)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0026, -0.0027, -0.0026,  ..., -0.0028, -0.0028, -0.0028]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1, rate1 = torchaudio.load(\"./data/jsut-japanese-dataset/loanword128/wav/LOANWORD128_003.wav\")\n",
    "array, rate = librosa.load(\"./data/spoken-language-identification/train/de_f_0809fd0642232f8c85b0b3d545dc2b5a.fragment1.flac\")\n",
    "\n",
    "array1\n",
    "#teste = librosa.amplitude_to_db(np.abs(librosa.stft(array1)), ref=np.max)\n",
    "#teste = torchaudio.transforms.Spectrogram(100)\n",
    "\n",
    "#librosa.display.specshow(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ipd.Audio(array, rate=rate)\n",
    "\n",
    "teste = np.pad(librosa.stft(array), [\n",
    "               (0, 0), (0, 50)], 'constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.pad(array, (0, 150000), 'constant', constant_values=0)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pyrb.pitch_shift(array, rate, -2.25)\n",
    "ipd.Audio(a, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
